#!/usr/bin/env bash
#BSUB -J sm4-qbc-phase2-submit
#BSUB -q gpu
#BSUB -n 1
#BSUB -M 2000
#BSUB -W 00:30
#BSUB -oo outputs/slurm_logs/%J.phase2_submit.out
#BSUB -eo outputs/slurm_logs/%J.phase2_submit.err

set -euo pipefail

# LSF (bsub) submit wrapper for Phase-2 QBC experiments.
# It first builds Phase-2 matrix from Phase-1 artifacts, then submits an LSF array.
#
# Required:
#   Set PHASE1_RUN_BASE below (or export before submission)
# Optional:
#   QUEUE, N_CORES, MEM_MB, WALL_HOURS, JOB_NAME
#   plus all knobs accepted by submit_qbc_phase2_from_phase1.sh

# Default points to your latest local Phase-1 run; change if needed.
PHASE1_RUN_BASE="${PHASE1_RUN_BASE:-outputs/qbc_sens/thesis_sm4_qbc_sens_local_evalrmse_20260225_093141}"
if [[ -z "${PHASE1_RUN_BASE}" ]]; then
  echo "[ERROR] PHASE1_RUN_BASE is required."
  echo "Example: PHASE1_RUN_BASE=outputs/qbc_sens/thesis_sm4_qbc_sens_local_evalrmse_20260225_093141 bash scripts/hpc/submit_qbc_phase2_from_phase1_lsf.sh"
  exit 1
fi

QUEUE="${QUEUE:-gpu}"
N_CORES="${N_CORES:-8}"
MEM_MB="${MEM_MB:-48000}"
WALL_HOURS="${WALL_HOURS:-24}"
JOB_NAME="${JOB_NAME:-sm4-qbc-phase2}"

PHASE2_EXPERIMENT_ID="${PHASE2_EXPERIMENT_ID:-thesis_sm4_qbc_phase2}"
STAMP="${STAMP:-$(date +%Y%m%d_%H%M%S)}"
PHASE2_RUN_BASE="${PHASE2_RUN_BASE:-outputs/qbc_phase2/${PHASE2_EXPERIMENT_ID}_${STAMP}}"

mkdir -p outputs/slurm_logs

# Build matrix only (no sbatch submission).
DRY_RUN=1 \
PHASE2_RUN_BASE="${PHASE2_RUN_BASE}" \
PHASE1_RUN_BASE="${PHASE1_RUN_BASE}" \
PHASE2_EXPERIMENT_ID="${PHASE2_EXPERIMENT_ID}" \
bash scripts/hpc/submit_qbc_phase2_from_phase1.sh

MATRIX_PATH="${PHASE2_RUN_BASE}/phase2_matrix.tsv"
if [[ ! -f "${MATRIX_PATH}" ]]; then
  echo "[ERROR] Matrix not found: ${MATRIX_PATH}"
  exit 1
fi

TOTAL_JOBS="$(( $(wc -l < "${MATRIX_PATH}") - 1 ))"
if (( TOTAL_JOBS <= 0 )); then
  echo "[ERROR] Empty matrix: ${MATRIX_PATH}"
  exit 1
fi

# Load shared-test root from metadata generated by matrix build.
META_PATH="${PHASE2_RUN_BASE}/phase2_meta.json"
if [[ ! -f "${META_PATH}" ]]; then
  echo "[ERROR] Metadata not found: ${META_PATH}"
  exit 1
fi

SHARED_TEST_ROOT="$(python - <<PY
import json
p = r'''${META_PATH}'''
with open(p, 'r', encoding='utf-8') as f:
    d = json.load(f)
print(d['shared_test_root'])
PY
)"

PHASE2_PHASE="${PHASE2_PHASE:-qbc_sensitivity}"
MODEL_FLAG="${MODEL_FLAG:-SM4}"
BASELINE_EPOCHS="${BASELINE_EPOCHS:-20}"
SURROGATE_DEVICE="${SURROGATE_DEVICE:-cuda}"
QBC_N_TEST="${QBC_N_TEST:-256}"
TIME_H="${TIME_H:-0.5}"
NUM_POINTS="${NUM_POINTS:-200}"
SHARED_TEST_MAX="${SHARED_TEST_MAX:-2048}"
BASELINE_BATCH_SIZE="${BASELINE_BATCH_SIZE:-128}"

echo "[INFO] Submitting LSF array with ${TOTAL_JOBS} jobs"
CMD="env PHASE2_RUN_BASE='${PHASE2_RUN_BASE}' MATRIX_PATH='${MATRIX_PATH}' SHARED_TEST_ROOT='${SHARED_TEST_ROOT}' PHASE2_EXPERIMENT_ID='${PHASE2_EXPERIMENT_ID}' PHASE2_PHASE='${PHASE2_PHASE}' MODEL_FLAG='${MODEL_FLAG}' BASELINE_EPOCHS='${BASELINE_EPOCHS}' SURROGATE_DEVICE='${SURROGATE_DEVICE}' QBC_N_TEST='${QBC_N_TEST}' TIME_H='${TIME_H}' NUM_POINTS='${NUM_POINTS}' SHARED_TEST_MAX='${SHARED_TEST_MAX}' BASELINE_BATCH_SIZE='${BASELINE_BATCH_SIZE}' bash scripts/hpc/lsf_array_qbc_phase2.sh"

echo "[INFO] bsub command:"
echo "bsub -J '${JOB_NAME}[1-${TOTAL_JOBS}]' -q '${QUEUE}' -n '${N_CORES}' -M '${MEM_MB}' -W '${WALL_HOURS}:00' -oo outputs/slurm_logs/${JOB_NAME}.%J.%I.out -eo outputs/slurm_logs/${JOB_NAME}.%J.%I.err \"${CMD}\""

bsub \
  -J "${JOB_NAME}[1-${TOTAL_JOBS}]" \
  -q "${QUEUE}" \
  -n "${N_CORES}" \
  -M "${MEM_MB}" \
  -W "${WALL_HOURS}:00" \
  -oo "outputs/slurm_logs/${JOB_NAME}.%J.%I.out" \
  -eo "outputs/slurm_logs/${JOB_NAME}.%J.%I.err" \
  "${CMD}"
